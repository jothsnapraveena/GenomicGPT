{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "#from langchain.chat_models import ChatOpenAI\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "import json\n",
    "import os\n",
    "os.environ[\"USER_AGENT\"] = \"agent1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AgenticRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# ‚úÖ Test Function\\ngene = \"BRCA1\"\\ndisease = \"Breast Cancer\"\\narticles = fetch_ncbi_bookshelf_articles(gene, disease)\\n\\n# ‚úÖ Print Retrieved Articles\\nfor idx, article in enumerate(articles[\"review_articles\"], 1):\\n    print(f\"{idx}. {article[\\'title\\']}\")\\n    print(f\"   URL: {article[\\'url\\']}\")\\'\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_ncbi_bookshelf_articles(gene, disease):\n",
    "    \"\"\"Fetches review articles for a gene-disease pair from NCBI Bookshelf.\"\"\"\n",
    "    \n",
    "    search_query = f\"{gene} {disease} review\"\n",
    "    url = f\"https://www.ncbi.nlm.nih.gov/books/?term={search_query.replace(' ', '+')}\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        return {\"error\": \"NCBI Bookshelf request failed\"}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    review_articles = []\n",
    "    for rev in soup.find_all(\"p\", class_=\"title\")[:5]:  # ‚úÖ Fetch top 5 reviews\n",
    "        review_title = rev.text.strip()\n",
    "        \n",
    "        # ‚úÖ Fetch NCBI Bookshelf URL (Relative -> Absolute)\n",
    "        article_link = rev.find(\"a\")[\"href\"]\n",
    "        full_url = f\"https://www.ncbi.nlm.nih.gov{article_link}\"\n",
    "        \n",
    "        # ‚úÖ Store metadata (Title + URL)\n",
    "        review_articles.append({\n",
    "            \"title\": review_title,\n",
    "            \"url\": full_url\n",
    "        })\n",
    "\n",
    "    return {\"review_articles\": review_articles}\n",
    "\n",
    "'''\n",
    "# ‚úÖ Test Function\n",
    "gene = \"BRCA1\"\n",
    "disease = \"Breast Cancer\"\n",
    "articles = fetch_ncbi_bookshelf_articles(gene, disease)\n",
    "\n",
    "# ‚úÖ Print Retrieved Articles\n",
    "for idx, article in enumerate(articles[\"review_articles\"], 1):\n",
    "    print(f\"{idx}. {article['title']}\")\n",
    "    print(f\"   URL: {article['url']}\")'\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scholarly import scholarly\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# def get_citations_from_scholar(article_title):\n",
    "#     \"\"\"Fetch citation count for a review article using Google Scholar.\"\"\"\n",
    "#     try:\n",
    "#         search_query = scholarly.search_pubs(article_title)\n",
    "#         result = next(search_query, None)  # Get the first result\n",
    "        \n",
    "        \n",
    "#         if result:\n",
    "#             return result[\"num_citations\"]  # Extract the citation count\n",
    "#         else:\n",
    "#             return 0  # No citations found\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error fetching citations for {article_title}: {e}\")\n",
    "#         return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citations(article_title):\n",
    "    \"\"\"Fetch citation count for a review article using multiple sources (CrossRef, OpenAlex, Semantic Scholar).\"\"\"\n",
    "\n",
    "    # ‚úÖ Try CrossRef first\n",
    "    citations = get_citations_from_crossref(article_title)\n",
    "    if citations > 0:\n",
    "        return citations\n",
    "\n",
    "\n",
    "# ‚úÖ Fetch Citations via CrossRef API\n",
    "def get_citations_from_crossref(article_title):\n",
    "    \"\"\"Fetches citation count for an article from CrossRef API.\"\"\"\n",
    "    url = f\"https://api.crossref.org/works?query.title={article_title}\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        data = response.json()\n",
    "\n",
    "        for item in data[\"message\"][\"items\"]:\n",
    "            if \"is-referenced-by-count\" in item:\n",
    "                return item[\"is-referenced-by-count\"]\n",
    "\n",
    "        return 0  # No citations found\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error fetching citations from CrossRef for {article_title}: {e}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_ncbi_bookshelf_articles(gene, disease):\n",
    "    \"\"\"Fetches review articles for a gene-disease pair from NCBI Bookshelf and ranks them by citations.\"\"\"\n",
    "    \n",
    "    search_query = f\"{gene} {disease} review\"\n",
    "    url = f\"https://www.ncbi.nlm.nih.gov/books/?term={search_query.replace(' ', '+')}\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        return {\"error\": \"NCBI Bookshelf request failed\"}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    review_articles = []\n",
    "    for rev in soup.find_all(\"p\", class_=\"title\")[:5]:  # ‚úÖ Fetch top 5 reviews\n",
    "        review_title = rev.text.strip()\n",
    "        \n",
    "        # ‚úÖ Fetch NCBI Bookshelf URL (Relative -> Absolute)\n",
    "        article_link = rev.find(\"a\")[\"href\"]\n",
    "        full_url = f\"https://www.ncbi.nlm.nih.gov{article_link}\"\n",
    "        \n",
    "        # ‚úÖ Fetch citation count from Google Scholar\n",
    "        citations = get_citations_from_crossref(review_title)\n",
    "        \n",
    "        # ‚úÖ Store metadata (Title + URL + Citations)\n",
    "        review_articles.append({\n",
    "            \"title\": review_title,\n",
    "            \"url\": full_url,\n",
    "            \"citations\": citations\n",
    "        })\n",
    "\n",
    "    # ‚úÖ Sort articles by number of citations (Descending)\n",
    "    review_articles.sort(key=lambda x: x[\"citations\"], reverse=True)\n",
    "\n",
    "    return {\"review_articles\": review_articles}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG for top 5 cited articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_articles_with_webloader(review_articles):\n",
    "    \"\"\"Loads full text from review article URLs using LangChain WebLoader.\"\"\"\n",
    "    docs = []\n",
    "    \n",
    "    for article in review_articles:\n",
    "        url = article[\"url\"]\n",
    "        print(f\"üåê Scraping: {url}\")\n",
    "        \n",
    "        try:\n",
    "            loader = WebBaseLoader(url)\n",
    "            docs.extend(loader.load())\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading {url}: {e}\")\n",
    "    \n",
    "    return docs  # ‚úÖ Returns extracted documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_articles(docs):\n",
    "    \"\"\"Splits loaded documents into smaller chunks for efficient storage.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,  # ‚úÖ Each chunk = 1000 characters\n",
    "        chunk_overlap=200  # ‚úÖ Allow 200 character overlap\n",
    "    )\n",
    "    \n",
    "    return text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_in_chromadb(chunks):\n",
    "    \"\"\"Stores document chunks in ChromaDB using OpenAI embeddings.\"\"\"\n",
    "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embedding_model\n",
    "    )\n",
    "\n",
    "    return vectorstore  # ‚úÖ Returns stored vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_docs(vectorstore, query, top_k=3):\n",
    "    \"\"\"Retrieves most relevant documents from ChromaDB for a given query.\"\"\"\n",
    "    return vectorstore.similarity_search(query, k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# import json\n",
    "\n",
    "# def predict_mechanism_with_rag(gene, disease, retrieved_docs):\n",
    "#     \"\"\"Predicts disease mechanism using retrieved literature and GPT-4.\"\"\"\n",
    "    \n",
    "#     evidence_text = \"\"\n",
    "#     for doc in retrieved_docs:\n",
    "#         evidence_text += f\"\\n\\n{doc.page_content[:2000]}\"  # ‚úÖ Limit to 2000 chars\n",
    "\n",
    "#     # ‚úÖ Prompt GPT-4 with retrieved evidence\n",
    "#     prompt = f\"\"\"\n",
    "#     Based on the following literature, determine the mechanism of disease for {gene} in {disease}:\n",
    "\n",
    "#     {evidence_text}\n",
    "\n",
    "#     Classify as:\n",
    "#     1. Loss of Function (LoF) - Mutation leads to reduced/absent protein function.\n",
    "#     2. Gain of Function (GoF) - Mutation leads to enhanced/new protein function.\n",
    "#     3. Dominant Negative (DN) - Mutant protein interferes with wild-type protein.\n",
    "\n",
    "#     Response format (JSON):\n",
    "#     {\n",
    "#         \"mechanism\": \"...\",\n",
    "#         \"justification\": \"...\"\n",
    "#     }\n",
    "#     \"\"\"\n",
    "    \n",
    "\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=\"gpt-4o\",\n",
    "#         messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "#     )\n",
    "\n",
    "#     return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import openai\n",
    "\n",
    "# ‚úÖ Initialize OpenAI client\n",
    "#client = openai.OpenAI()\n",
    "\n",
    "def predict_mechanism_with_rag(gene, disease, retrieved_docs):\n",
    "    \"\"\"Predicts disease mechanism using retrieved literature and GPT-4 with enforced JSON output.\"\"\"\n",
    "\n",
    "    # ‚úÖ Combine evidence from retrieved documents\n",
    "    evidence_text = \"\\n\\n\".join([doc.page_content[:2000] for doc in retrieved_docs])  # Limit text size\n",
    "\n",
    "    # ‚úÖ Construct structured prompt\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following scientific literature, determine the mechanism of disease for {gene} in {disease}:\n",
    "\n",
    "    {evidence_text}\n",
    "\n",
    "    Choose one of the following classifications:\n",
    "    - Loss of Function (LoF): Mutation leads to reduced/absent protein function.\n",
    "    - Gain of Function (GoF): Mutation leads to enhanced/new protein function.\n",
    "    - Dominant Negative (DN): Mutant protein interferes with wild-type protein.\n",
    "\n",
    "    Return a **valid JSON response** in this exact format:\n",
    "    {{\n",
    "        \"mechanism\": \"Loss of Function (LoF) | Gain of Function (GoF) | Dominant Negative (DN)\",\n",
    "        \"justification\": \"A concise explanation based on extracted evidence.\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # ‚úÖ Enforce JSON output\n",
    "        client=OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_format={\"type\": \"json_object\"}  # ‚úÖ Forces GPT-4 to return JSON\n",
    "        )\n",
    "\n",
    "        # ‚úÖ Parse and return JSON response\n",
    "        return json.loads(response.choices[0].message.content)  # Ensure valid JSON parsing\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error predicting mechanism: {e}\")\n",
    "        return {\"error\": \"Failed to predict mechanism\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_confidence_with_rag(gene, disease, review_articles):\n",
    "    \"\"\"Scores confidence of the predicted mechanism based on citation count.\"\"\"\n",
    "    \n",
    "    # ‚úÖ Use total citations from top 3 articles\n",
    "    total_citations = sum([article[\"citations\"] for article in review_articles[:3]])\n",
    "    confidence_score = min(10, total_citations // 100)  # Normalize to 1-10 scale\n",
    "    \n",
    "    return {\"mechanism\": \"Predicted Mechanism\", \"confidence_score\": confidence_score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autonomous_mechanism_discovery(gene, disease):\n",
    "    \"\"\"Runs the full mechanism discovery pipeline with LangChain WebLoader + ChromaDB.\"\"\"\n",
    "    \n",
    "    print(\"\\nüîç Step 1: Fetching Highly Cited Review Articles...\")\n",
    "    search_results = fetch_ncbi_bookshelf_articles(gene, disease)\n",
    "    review_articles = search_results[\"review_articles\"]\n",
    "    \n",
    "    print(\"\\nüåê Step 2: Scraping Articles Using LangChain WebLoader...\")\n",
    "    docs = load_articles_with_webloader(review_articles)\n",
    "\n",
    "    print(\"\\nüìÑ Step 3: Splitting Articles for Storage...\")\n",
    "    chunks = split_articles(docs)\n",
    "\n",
    "    print(\"\\nüóÑÔ∏è Step 4: Storing in ChromaDB...\")\n",
    "    vectorstore = store_in_chromadb(chunks)\n",
    "\n",
    "    print(\"\\nüîé Step 5: Retrieving Top Relevant Evidence...\")\n",
    "    retrieved_docs = retrieve_relevant_docs(vectorstore, f\"{gene} {disease} mechanism\", top_k=3)\n",
    "\n",
    "    print(\"\\nüß† Step 6: Predicting Mechanism Using RAG & GPT-4...\")\n",
    "    mechanism_result = predict_mechanism_with_rag(gene, disease, retrieved_docs)\n",
    "    \n",
    "    print(\"\\nüìä Step 7: Scoring Confidence Based on Citations...\")\n",
    "    confidence_score = score_confidence_with_rag(gene, disease, review_articles)\n",
    "\n",
    "    print(\"\\n‚úÖ Final Mechanism Report:\")\n",
    "    final_report = {\n",
    "        \"gene\": gene,\n",
    "        \"disease\": disease,\n",
    "        \"mechanism\": mechanism_result[\"mechanism\"],\n",
    "        \"confidence_score\": confidence_score[\"confidence_score\"],\n",
    "        \"justification\": mechanism_result[\"justification\"]\n",
    "    }\n",
    "\n",
    "    print(final_report)\n",
    "    return final_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Step 1: Fetching Highly Cited Review Articles...\n",
      "\n",
      "üåê Step 2: Scraping Articles Using LangChain WebLoader...\n",
      "üåê Scraping: https://www.ncbi.nlm.nih.gov/books/NBK545867/?term=BRCA1%20Breast%20Cancer%20review\n",
      "üåê Scraping: https://www.ncbi.nlm.nih.gov/books/NBK12354/?term=BRCA1%20Breast%20Cancer%20review\n",
      "üåê Scraping: https://www.ncbi.nlm.nih.gov/books/NBK82221/?term=BRCA1%20Breast%20Cancer%20review\n",
      "üåê Scraping: https://www.ncbi.nlm.nih.gov/books/NBK430685/?term=BRCA1%20Breast%20Cancer%20review\n",
      "üåê Scraping: https://www.ncbi.nlm.nih.gov/books/NBK179201/?term=BRCA1%20Breast%20Cancer%20review\n",
      "\n",
      "üìÑ Step 3: Splitting Articles for Storage...\n",
      "\n",
      "üóÑÔ∏è Step 4: Storing in ChromaDB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0k/yzqgz8q97fsgf52zq77j5tpc0000gn/T/ipykernel_22983/3642869916.py:3: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Step 5: Retrieving Top Relevant Evidence...\n",
      "\n",
      "üß† Step 6: Predicting Mechanism Using RAG & GPT-4...\n",
      "\n",
      "üìä Step 7: Scoring Confidence Based on Citations...\n",
      "\n",
      "‚úÖ Final Mechanism Report:\n",
      "{'gene': 'BRCA1', 'disease': 'Breast Cancer', 'mechanism': 'Loss of Function (LoF)', 'confidence_score': 2, 'justification': 'BRCA1 mutations in breast cancer typically result in a loss of function, as these mutations often lead to reduced or absent protein function which disrupts the DNA repair mechanism, thereby increasing the risk for cancer development.'}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # ‚úÖ Run the pipeline\n",
    "    report = autonomous_mechanism_discovery(\"BRCA1\", \"Breast Cancer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
